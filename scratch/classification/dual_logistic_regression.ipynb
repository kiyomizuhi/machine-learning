{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents:\n",
    "* [Maximum Likelihood logistic regression](#maxlike)\n",
    "* [Bayesian logistic regression](#bayesian)\n",
    "* [Non-linear logistic regression](#non-linear)\n",
    "* [Dual logistic regression](#dual)\n",
    "* [Relevance vector classification](#relevant-vector)\n",
    "* [Incremental fitting and boosting](#boosting)\n",
    "* [Classification trees](#trees)\n",
    "* [Multi-class logistic regression](#multiclass)\n",
    "* [Random trees, forests, and ferns](#forest)\n",
    "* [Multi-class logistic regression](#multiclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as spsp\n",
    "import scipy.stats as spst\n",
    "%matplotlib inline\n",
    "\n",
    "# usual gangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data_set_dim1_nonlinear(ns):\n",
    "    \"\"\"\n",
    "    this function generates a 1d data set of two classes which are linearly separated.\n",
    "    \n",
    "    Arguments:\n",
    "        ns: number of samples\n",
    "    \n",
    "    Output:\n",
    "        ds1   : data on the negative side (2, ns). ds1[1] = 0 is the label.\n",
    "        ds2   : data on the positive side (2, ns). ds2[1] = 1 is the label.\n",
    "        data  : data combined ds1 and ds2 and shuffled. (1, ns)\n",
    "        label : label combined ds1 and ds2 and shuffled. (1, ns)\n",
    "        datab : data combined ds1 and ds2 and shuffled. data1[0] = 1 for bias. (2, ns)\n",
    "    \"\"\"\n",
    "    ns_neg1 = int(0.3 * ns)\n",
    "    ns_neg2 = int(0.2 * ns)\n",
    "    ns_neg  = ns_neg1 + ns_neg2\n",
    "    ns_pos1 = int(0.3 * ns)\n",
    "    ns_pos2 = ns - ns_neg1 - ns_neg2 - ns_pos1\n",
    "    ns_pos  = ns_pos1 + ns_pos2\n",
    "    mus = [-6, 2, 6, -2]\n",
    "    \n",
    "    dt_neg1 = np.random.standard_t(3, size=ns_neg1) + mus[0]\n",
    "    dt_neg2 = np.random.standard_t(3, size=ns_neg2) + mus[1]\n",
    "    ds1 = np.hstack((dt_neg1, dt_neg2))\n",
    "    ds1 = np.vstack((ds1, np.zeros(ns_neg)))\n",
    "    \n",
    "    dt_pos1 = np.random.standard_t(3, size=ns_pos1) + mus[2]\n",
    "    dt_pos2 = np.random.standard_t(3, size=ns_pos2) + mus[3]\n",
    "    ds2 = np.hstack((dt_pos1, dt_pos2))\n",
    "    ds2 = np.vstack((ds2, np.ones(ns_pos)))\n",
    "    \n",
    "    ds = np.hstack((ds1, ds2))\n",
    "    np.random.shuffle(ds.T)\n",
    "    data = ds[0]\n",
    "    label = ds[1][np.newaxis, :]\n",
    "    datab = np.vstack((np.ones(ns), data))\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (5.0, 3.0)\n",
    "    plt.plot(ds1[0], ds1[1], 'r.', markersize=3)\n",
    "    plt.plot(ds2[0], ds2[1], 'b.', markersize=3)\n",
    "    return data, label, datab\n",
    "\n",
    "\n",
    "def generate_data_set_dim2_linear(ns):\n",
    "    \"\"\"\n",
    "    this function generates a 2d data set of two classes which are linearly separated.\n",
    "    \n",
    "    Arguments:\n",
    "        ns: number of samples\n",
    "    \n",
    "    Output:\n",
    "        ds1: data on the negative side (3, ns). ds1[1] = 0 is the label.\n",
    "        ds2: data on the positive side (3, ns). ds2[1] = 0 is the label.\n",
    "        data  : data combined ds1 and ds2 and shuffled. (2, ns)\n",
    "        label : label combined ds1 and ds2 and shuffled. (2, ns)\n",
    "        datab : data combined ds1 and ds2 and shuffled. datab[0] = 1 for bias. (3, ns)\n",
    "    \"\"\"\n",
    "    ns_neg = int(0.4 * ns)\n",
    "    ns_pos = int(0.4 * ns)\n",
    "    ns_pen = ns - ns_neg - ns_pos\n",
    "    nfar_neg = int(0.7 * ns_neg)\n",
    "    nbdr_neg = ns_neg - nfar_neg\n",
    "    nfar_pos = int(0.7 * ns_pos)\n",
    "    nbdr_pos = ns_pos - nfar_pos\n",
    "    \n",
    "    far_neg = 8 * (np.random.rand(nfar_neg) - .5) - 5\n",
    "    bdr_neg = np.random.standard_t(4, size=nbdr_neg) - 0.5\n",
    "    ds1x = np.hstack((far_neg, bdr_neg, bdr_pen))\n",
    "    ds1y = 10 * (np.random.rand(ns_neg) - .5)\n",
    "    ds1 = np.vstack((ds1x, ds1y))\n",
    "    \n",
    "    far_pos = 8 * (np.random.rand(nfar_pos) - .5) + 5\n",
    "    bdr_pos = np.random.standard_t(4, size=nbdr_pos) + 0.5\n",
    "    ds2x = np.hstack((far_pos, bdr_pos))\n",
    "    ds2y = 10 * (np.random.rand(ns_pos) - .5)\n",
    "    ds2 = np.vstack((ds2x, ds2y))\n",
    "    \n",
    "    ang = np.pi * np.random.rand() \n",
    "    c, s = np.cos(ang), np.sin(ang)\n",
    "    rot = np.array([[c, s], [-s, c]])\n",
    "    \n",
    "    ds1 = np.dot(rot, ds1)\n",
    "    ds2 = np.dot(rot, ds2)\n",
    "    \n",
    "    ds1 = np.vstack((ds1, np.zeros(ns_neg)))\n",
    "    ds2 = np.vstack((ds2, np.ones(ns_pos)))\n",
    "    ds = np.hstack((ds1, ds2))\n",
    "    np.random.shuffle(ds.T)\n",
    "    \n",
    "    data = ds[:2]\n",
    "    label = ds[2][np.newaxis, :]\n",
    "    datab = np.vstack((np.ones(ns), data))\n",
    "    \n",
    "    #plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "    #plt.plot(ds1[0], ds1[1], 'r.', markersize=3)\n",
    "    #plt.plot(ds2[0], ds2[1], 'b.', markersize=3)\n",
    "    return ds1, ds2, data, label, datab, ang\n",
    "\n",
    "\n",
    "def cost_function(z, w, phi):\n",
    "    \"\"\"\n",
    "    this function computes logistic cost function\n",
    "    \n",
    "    Arguments:\n",
    "        z   :  (K + 1, N)  1 is for bias.\n",
    "        w   :  (1, N)\n",
    "        phi :  (1, K + 1)\n",
    "    \n",
    "    Output:\n",
    "        L:     scalar. cost function.\n",
    "    \"\"\"\n",
    "    sig = sigmoid(z, phi)\n",
    "    wlogsig1 = np.dot(w, np.log(sig))\n",
    "    wlogsig2 = np.dot(1 - w, np.log(1 - sig))\n",
    "    L = wlogsig1 + wlogsig2\n",
    "    return L\n",
    "\n",
    "    \n",
    "def sigmoid(z, phi):\n",
    "    \"\"\"\n",
    "    this function computes sigmoid function\n",
    "    \n",
    "    Arguments:\n",
    "        z   :  (K + 1, N)  1 is for bias.\n",
    "        phi :  (1, K + 1)\n",
    "    \n",
    "    Output:\n",
    "        sig  :  (N, 1)\n",
    "    \"\"\"\n",
    "    phix = np.dot(phi, z)\n",
    "    denom = 1 + np.exp(-phix) \n",
    "    sig = 1 / denom\n",
    "    return sig.T\n",
    "\n",
    "\n",
    "def da_dphi(z):\n",
    "    \"\"\"\n",
    "    this function generates da/dphi.\n",
    "    \n",
    "    Arguments:\n",
    "        z: generated bases including bias at the zeroth row. ((K+1), N).\n",
    "    \n",
    "    Output:\n",
    "        z: da/dphi. ((K+1), N)\n",
    "    \"\"\"\n",
    "    return z\n",
    "\n",
    "\n",
    "def da_dalp(z, x, phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function generates da/dalp.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1), N).\n",
    "        x  : original cooridnates of the samples. (D, N)\n",
    "        phi: phi. (1, (K+1))\n",
    "        alp: alpha. (D, K)\n",
    "        lmd: scalar.\n",
    "    \n",
    "    Intermediate:\n",
    "        pf    : (K+1, N)\n",
    "        pfx   : (K*D, N)\n",
    "        xx    : (K*D, N)\n",
    "        alpx  : (K*D, 1)\n",
    "\n",
    "    Output:\n",
    "        da/dalp: (K*D, N)\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    N = x.shape[1]\n",
    "    pf = phi.T * z / lmd\n",
    "    pfx = np.kron(pf[1:], np.ones((D, 1)))\n",
    "    xx = np.tile(x, (K, 1))\n",
    "    alpx = np.reshape(alp.T, (D*K, 1))\n",
    "    dadalp = pfx * (xx - alpx)\n",
    "    return dadalp\n",
    "\n",
    "\n",
    "def da_dtheta(z, x, phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function generates da/dtheta.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x  : original cooridnates of the samples. (D, N)\n",
    "        phi: phi. (1, (K+1))\n",
    "        alp: alpha. (D, K)\n",
    "        lmd: scalar.\n",
    "\n",
    "    Output:\n",
    "        da/dtheta: ((K+1+KD), N)\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    K1 = z.shape[0]\n",
    "    N = x.shape[1]\n",
    "    dadtht = np.zeros((K1 + K*D, N))\n",
    "    dadtht[:K1, :] = da_dphi(z)\n",
    "    dadtht[K1:, :] = da_dalp(z, x, phi, alp, lmd)\n",
    "    return dadtht\n",
    "\n",
    "\n",
    "def dda_dphi_dphi(z):\n",
    "    \"\"\"\n",
    "    this function generates dda/dphidphi.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "\n",
    "    Output:\n",
    "        dda/dphidphi: ((K+1), (K+1))\n",
    "    \"\"\"\n",
    "    K1 = z.shape[0]\n",
    "    N  = z.shape[1]\n",
    "    ddadphidphi = np.zeros((K1, K1, N))\n",
    "    return ddadphidphi\n",
    "\n",
    "\n",
    "def dda_dphi_dalp(z, x, phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function generates dda/dphidalp.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x  : original cooridnates of the samples. (D, N)\n",
    "        phi: phi. (1, (K+1))\n",
    "        alp: alpha. (D, K)\n",
    "        lmd: scalar.\n",
    "    \n",
    "    Intermediate:\n",
    "        pf    : (K+1, N)\n",
    "        pfx   : (K*D, N)\n",
    "        xx    : (K*D, N)\n",
    "        alpx  : (K*D, 1)\n",
    "        dlt   : (K*D, N)\n",
    "\n",
    "    Output:\n",
    "        ddadphidalp: (KD, K, N)\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    K1 = z.shape[0]\n",
    "    N = x.shape[1]\n",
    "    pf = z/lmd\n",
    "    pfx = np.kron(pf[1:], np.ones((D, 1)))\n",
    "    xx = np.tile(x, (K, 1))\n",
    "    alpx = alp.reshape(D*K, 1)\n",
    "    dlt = pfx * (xx - alpx)\n",
    "    ddadphidalp = np.tile(dlt[:, np.newaxis, :], (1, K, 1))\n",
    "    return ddadphidalp\n",
    "\n",
    "\n",
    "def dda_dalp_dalp(z, x, phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function generates dda/dphidalp.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x  : original cooridnates of the samples. (D, N)\n",
    "        phi: phi. (1, (K+1))\n",
    "        alp: alpha. (D, K)\n",
    "        lmd: scalar.\n",
    "    \n",
    "    Intermediate:\n",
    "        pf    : (K+1, N)\n",
    "        pfx   : (K*D, N)\n",
    "        xx    : (K*D, N)\n",
    "        alpx  : (K*D, 1)\n",
    "        dlt   : (K*D, N)\n",
    "\n",
    "    Output:\n",
    "        da/dtheta: ((K+1+KD), N)\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    K1 = z.shape[0]\n",
    "    N = x.shape[1]\n",
    "    pf = phi.T * z / lmd\n",
    "    xx = np.tile(x[:, np.newaxis, :], (1, K, 1))\n",
    "    alpx = np.tile(alp[:, :, np.newaxis], (D, 1, 1))\n",
    "    dlt = xx - alpx\n",
    "    dltx = dlt[np.newaxis, :, :, :]\n",
    "    dltxT = dlt[:, np.newaxis, :, :]\n",
    "    pare = (dltxT * dltx)/lmd\n",
    "    pare -= np.eye(D)[:, :, np.newaxis,  np.newaxis]\n",
    "    dda_dpda = np.zeros((K*D, K*D, N))\n",
    "    for k in range(K):\n",
    "        dda_dpda[D*k:D*(k+1), D*k:D*(k+1), :] = pare[:, :, k, :] * pf[k, :]\n",
    "    return dda_dpda\n",
    "\n",
    "\n",
    "def dda_dtheta_dtheta(z, x, phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function generates dda/dphidalp.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x  : original cooridnates of the samples. (D, N)\n",
    "        phi: phi. (1, (K+1))\n",
    "        alp: alpha. (D, K)\n",
    "        lmd: scalar.\n",
    "\n",
    "    Output:\n",
    "        da/dtheta: ((K+1+KD), N)\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    K1 = z.shape[0]\n",
    "    N = x.shape[1]\n",
    "    nn = K1 + K*D\n",
    "    ddadtdt = np.zeros((nn, nn, N))\n",
    "    ddadtdt[:K1, :K1, :] = dda_dphi_dphi(z)\n",
    "    ddadpda = dda_dphi_dalp(z, x, phi, alp, lmd)\n",
    "    ddadtdt[K1:, 1:K1, :] = ddadpda\n",
    "    ddadtdt[1:K1, K1:, :] = np.swapaxes(ddadpda, 0, 1)\n",
    "    ddadtdt[K1:, K1:,  :] = dda_dalp_dalp(z, x, phi, alp, lmd)\n",
    "    return ddadtdt\n",
    "\n",
    "\n",
    "def dL_dtheta(z, x, w, phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function generates dda/dphidalp.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x  : original cooridnates of the samples. (D, N)\n",
    "        w  : label. (1, N)\n",
    "        phi: phi. (1, (K+1))\n",
    "        alp: alpha. (D, K)\n",
    "        lmd: scalar.\n",
    "    \n",
    "    Intermediate:\n",
    "        sig   : (N, 1)\n",
    "        dadt  : ((K+1+KD), N)\n",
    "        dlt   : (1, N)\n",
    "\n",
    "    Output:\n",
    "        dLdt: ((K+1+KD), 1)\n",
    "    \"\"\"\n",
    "    dadt = da_dtheta(z, x, phi, alp, lmd)\n",
    "    sig = sigmoid(z, phi)\n",
    "    dLdt = np.dot(dadt, w.T - sig)\n",
    "    dLdt *= -1\n",
    "    return dLdt\n",
    "\n",
    "\n",
    "def ddL_dtheta_dtheta(z, x, w, phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function generates dda/dphidalp.\n",
    "    \n",
    "    Arguments:\n",
    "        z  : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x  : original cooridnates of the samples. (D, N)\n",
    "        w  : label. (1, N)\n",
    "        phi: phi. (1, (K+1))\n",
    "        alp: alpha. (D, K)\n",
    "        lmd: scalar.\n",
    "    \n",
    "    Intermediate:\n",
    "        sig   : (N, 1)\n",
    "        dadt  : ((K+1+KD), N)\n",
    "        dlt   : (1, N)\n",
    "        err   : (N, )\n",
    "\n",
    "    Output:\n",
    "        ddLdtdt: ((K+1+KD), (K+1+KD))\n",
    "    \"\"\"\n",
    "    dadt = da_dtheta(z, x, phi, alp, lmd)\n",
    "    dadts = dadt[np.newaxis, :, :] * dadt[:, np.newaxis, :]\n",
    "    ddadtdt = dda_dtheta_dtheta(z, x, phi, alp, lmd)\n",
    "    sig = sigmoid(z, phi)\n",
    "    err = (w - sig.T).squeeze()\n",
    "    sigsig1 = (sig * (sig - 1)).squeeze()\n",
    "    ddLdtdt = np.einsum('i,jki->jk', sigsig1, dadts)\n",
    "    ddLdtdt -= np.einsum('i,jki->jk', err, ddadtdt)\n",
    "    ddLdtdt *= -1\n",
    "    return ddLdtdt\n",
    "\n",
    "\n",
    "def newton_method_update(z, x, w, phi, alp, beta, lmd):\n",
    "    \"\"\"\n",
    "    this function computes sigmoid function\n",
    "    \n",
    "    Arguments:\n",
    "        z    : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x    : original cooridnates of the samples. (D, N)\n",
    "        phi  : phi. (1, (K+1))\n",
    "        alp  : alpha. (D, K)\n",
    "        beta : scalar. learning rate.\n",
    "        lmd  : scalar.\n",
    "    \n",
    "    Intermediate:\n",
    "        dLdt   : ((K+1+KD), 1)\n",
    "        ddLdtdt: ((K+1+KD), (K+1+KD))\n",
    "        \n",
    "    Output:\n",
    "        theta: (1, (K+1+KD))\n",
    "    \"\"\"\n",
    "    D = x.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    K1 = z.shape[0]\n",
    "    N = x.shape[1]\n",
    "    theta = np.hstack((phi, alp.T.reshape(1, K*D)))\n",
    "    dLdt    = dL_dtheta(z, x, w, phi, alp, lmd)\n",
    "    ddLdtdt = ddL_dtheta_dtheta(z, x, w, phi, alp, lmd)\n",
    "    ddLdtdt_inv = np.linalg.inv(ddLdtdt)\n",
    "    theta -= beta * np.dot(ddLdtdt_inv, dLdt).T\n",
    "    phi = theta[0, :K1].reshape(1, K1)\n",
    "    alp = theta[0, K1:].reshape(K, D).T\n",
    "    return phi, alp\n",
    "    \n",
    "    \n",
    "def newton_method(z, x, w, phi, alp, beta, lmd):\n",
    "    \"\"\"\n",
    "    this function computes sigmoid function\n",
    "    \n",
    "    Arguments:\n",
    "        z    : generated bases including bias at the zeroth row. ((K+1) * N).\n",
    "        x    : original cooridnates of the samples. (D, N)\n",
    "        phi  : phi. (1, (K+1))\n",
    "        alp  : alpha. (D, K)\n",
    "        beta : scalar. learning rate.\n",
    "        lmd  : scalar.\n",
    "        \n",
    "    Output:\n",
    "        theta: (1, (K+1+KD))\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    D = x.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    K1 = z.shape[0]\n",
    "    N = x.shape[1]\n",
    "    nn = K1 + K * D\n",
    "    dlt = 1\n",
    "    step = 0\n",
    "    thetas = np.zeros((10000, nn))\n",
    "    theta = np.hstack((phi, alp.T.reshape(1, K*D)))\n",
    "    thetas[step, :] = theta\n",
    "    while dlt > 0.001:\n",
    "        step += 1\n",
    "        temp = copy.deepcopy(theta)\n",
    "        phi, alp = newton_method_update(z, x, w, phi, alp, beta, lmd)       \n",
    "        theta = np.hstack((phi, alp.T.reshape(1, K*D)))\n",
    "        thetas[step, :] = theta\n",
    "        dlt = np.max(np.abs(temp - theta)/temp)\n",
    "    strng = '{:d} steps done: \\n'.format(step + 1)\n",
    "    for i in range(nn):\n",
    "        strng += '{:1.4f}, '.format(theta.squeeze()[i])\n",
    "    print(strng)\n",
    "    thetas = thetas[:(step + 1), :]\n",
    "    phi = theta[0, :K1].reshape(1, K1)\n",
    "    alp = theta[0, K1:].reshape(K, D).T\n",
    "    return phi, alp, thetas, thetas\n",
    "\n",
    "\n",
    "def maximum_a_posterior(datab, label, phi, alpha, sgp):\n",
    "    \"\"\"\n",
    "    this function computes sigmoid function\n",
    "    \n",
    "    Arguments:\n",
    "        datab:   (D, ns)  D contains bias as well.\n",
    "        label:   (1, ns)\n",
    "        phi  :   (1, D)\n",
    "        alpha:   scalar\n",
    "        sgp  :   scalar. prior sigma\n",
    "    \n",
    "    Output:\n",
    "        mu_map   :  (D, 1). MAP phi.\n",
    "        sgms_map :  (D, D). MAP sigma squared.\n",
    "    \"\"\"\n",
    "    phi, _ = newton_method(datab, label, phi, alpha, sgp)\n",
    "    mu_map = phi\n",
    "    hess = dL_hess(datab, phi, sgp)\n",
    "    sgms_map = -np.linalg.inv(hess)\n",
    "    return mu_map, sgms_map\n",
    "\n",
    "\n",
    "def bayesian_inference(mu, sgms, nres):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        mu:    (1, D). MAP phi\n",
    "        sgma:  (D, D). MAP sigma squared\n",
    "        nres:  resolution of the curve/image\n",
    "        \n",
    "    Output:\n",
    "        plot.\n",
    "    \"\"\"\n",
    "    D = mu.shape[1]\n",
    "    if D == 3:\n",
    "        nn = nres**2\n",
    "        xres = np.linspace(-10, 10, nres)\n",
    "        yres = np.linspace(-10, 10, nres)\n",
    "        yg, xg = np.meshgrid(yres, xres)\n",
    "        x_flat = xg.reshape(1, nn)\n",
    "        y_flat = yg.reshape(1, nn)\n",
    "        x1_flat = np.vstack((np.ones(nn), x_flat))\n",
    "        xy1_flat = np.vstack((x1_flat, y_flat))\n",
    "        mus  = np.dot(phi, xy1_flat)\n",
    "        sgmss = (np.dot(sgms, xy1_flat) * xy1_flat).sum(axis=0)\n",
    "        arg = np.sqrt(1 + np.pi * sgmss / 8)\n",
    "        denom = 1 + np.exp(-mus / arg)\n",
    "        lmbd = 1 / denom\n",
    "        lmbd = lmbd.reshape((nres, nres)).T\n",
    "        lmbd = np.fliplr(lmbd)\n",
    "        return lmbd\n",
    "    elif D == 2:\n",
    "        xres = np.linspace(-10, 10, nres)\n",
    "        x1_flat = np.vstack((np.ones(nres), xres))\n",
    "        mus  = np.dot(phi, x1_flat)\n",
    "        sgmss = (np.dot(sgms, x1_flat) * x1_flat).sum(axis=0)\n",
    "        arg = np.sqrt(1 + np.pi * sgmss / 8)\n",
    "        denom = 1 + np.exp(-mus / arg)\n",
    "        lmbd = 1 / denom\n",
    "        return lmbd\n",
    "    else:\n",
    "        print('We don''t cover such case here')\n",
    "\n",
    "\n",
    "def radial_basis(x, ng, lmd):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        x:    (1, nx). nx number of x coordinates. could be grid, could be samples.\n",
    "        ng:   scalar. number of gaussians to use. \n",
    "        lmd:  scalar. std of the gaussian.\n",
    "        \n",
    "    Output:\n",
    "        bases: (D, nx).\n",
    "    \"\"\"\n",
    "    D = ng + 1\n",
    "    nx = x.shape[0]\n",
    "    mus = 12 * (np.random.rand(ng) - 0.5)\n",
    "    bases = np.ones((D, nx))\n",
    "    for i in range(1, D):\n",
    "        bases[i, :] = spst.norm.pdf(x, mus[i - 1], lmd)\n",
    "    return bases\n",
    "\n",
    "\n",
    "def plot_decision_boundary_dim1(phi, alp, lmd):\n",
    "    \"\"\"\n",
    "    this function computes sigmoid function\n",
    "    \n",
    "    Arguments:\n",
    "        phi  : phi. (1, (K+1))\n",
    "        alp  : alpha. (D, K)\n",
    "        beta : scalar. learning rate.\n",
    "        lmd  : scalar.\n",
    "    \n",
    "    Intermediate:\n",
    "        dLdt   : ((K+1+KD), 1)\n",
    "        ddLdtdt: ((K+1+KD), (K+1+KD))\n",
    "        \n",
    "    Output:\n",
    "        theta: (1, (K+1+KD))\n",
    "    \"\"\"\n",
    "    D = alp.shape[0]\n",
    "    K = alp.shape[1]\n",
    "    K1 = phi.shape[1]\n",
    "    nx = 201\n",
    "    x = np.linspace(-10, 10, nx)\n",
    "    z = np.ones((K1, nx))\n",
    "    for i in range(1, K1):\n",
    "        z[i, :] = spst.norm.pdf(x, alp[:, i-1].squeeze(), lmd)\n",
    "    dbdr = sigmoid(z, phi)\n",
    "    return x, dbdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
