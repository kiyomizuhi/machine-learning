# machine-learning

Here I follow the following book and implement the algorithms therein from scratch as a means to learn the subject.
Computer Vision: Models, Learning, and Inference by Dr Simon J. D. Prince https://www.amazon.com/dp/1107011795/ref=cm_sw_r_tw_dp_U_x_.jwjAbJCPWTQR
http://www.computervisionmodels.com/

The diagrams below are from the book therein.

## Table of contents:

### EM algorithms (discrete & continuous latent variables)
  - Generalities
  - Gaussian Mixture (discrete mixture) 
  - Gaussian Mixture (continuous mixture in covariance)
  - Gaussian Mixture (continuous mixture in mean) AKA Factor Analysis
  - Discrete Student's-T Mixture

<img width="804" alt="screen shot 2017-12-10 at 2 25 29 am" src="https://user-images.githubusercontent.com/19827262/33800827-9749f2e6-dd51-11e7-9953-e748536d9676.png">

### Regression models
  - Maximum Likelihood Linear Regression
  - Bayesian linear regression
  - Non-linear regression
  - Kernel trick and Gaussian process regression
  - Sparse linear regression
  - Dual linear regression
  - Relevance vector regression

<img width="747" alt="screen shot 2017-12-10 at 2 29 01 am" src="https://user-images.githubusercontent.com/19827262/33800840-ebc26236-dd51-11e7-8898-a626bff9dd8c.png">

### Classification models
  - Maximum Likelihood logistic regression
  - Bayesian logistic regression
  - Non-linear logistic regression
  - Dual logistic regression
  - Relevance vector classification
  - Incremental fitting and boosting
  - Classification trees
  - Multi-class logistic regression
  - Random trees, forests, and ferns
  - Multi-class logistic regression
  
  <img width="924" alt="screen shot 2017-12-14 at 2 19 11 pm" src="https://user-images.githubusercontent.com/19827262/33992106-fff0c5c8-e0d9-11e7-87f0-2f56b13a0f8c.png">
